// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"reflect"
	"testing"

	"github.com/stretchr/testify/assert"
	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/receiver/receivertest"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"
)

func TestDefaultMetrics(t *testing.T) {
	start := pcommon.Timestamp(1_000_000_000)
	ts := pcommon.Timestamp(1_000_001_000)
	mb := NewMetricsBuilder(DefaultMetricsSettings(), receivertest.NewNopCreateSettings(), WithStartTime(start))
	enabledMetrics := make(map[string]bool)

	enabledMetrics["riak.memory.limit"] = true
	mb.RecordRiakMemoryLimitDataPoint(ts, 1)

	enabledMetrics["riak.node.operation.count"] = true
	mb.RecordRiakNodeOperationCountDataPoint(ts, 1, AttributeRequest(1))

	enabledMetrics["riak.node.operation.time.mean"] = true
	mb.RecordRiakNodeOperationTimeMeanDataPoint(ts, 1, AttributeRequest(1))

	enabledMetrics["riak.node.read_repair.count"] = true
	mb.RecordRiakNodeReadRepairCountDataPoint(ts, 1)

	enabledMetrics["riak.vnode.index.operation.count"] = true
	mb.RecordRiakVnodeIndexOperationCountDataPoint(ts, 1, AttributeOperation(1))

	enabledMetrics["riak.vnode.operation.count"] = true
	mb.RecordRiakVnodeOperationCountDataPoint(ts, 1, AttributeRequest(1))

	metrics := mb.Emit()

	assert.Equal(t, 1, metrics.ResourceMetrics().Len())
	sm := metrics.ResourceMetrics().At(0).ScopeMetrics()
	assert.Equal(t, 1, sm.Len())
	ms := sm.At(0).Metrics()
	assert.Equal(t, len(enabledMetrics), ms.Len())
	seenMetrics := make(map[string]bool)
	for i := 0; i < ms.Len(); i++ {
		assert.True(t, enabledMetrics[ms.At(i).Name()])
		seenMetrics[ms.At(i).Name()] = true
	}
	assert.Equal(t, len(enabledMetrics), len(seenMetrics))
}

func TestAllMetrics(t *testing.T) {
	start := pcommon.Timestamp(1_000_000_000)
	ts := pcommon.Timestamp(1_000_001_000)
	metricsSettings := MetricsSettings{
		RiakMemoryLimit:              MetricSettings{Enabled: true},
		RiakNodeOperationCount:       MetricSettings{Enabled: true},
		RiakNodeOperationTimeMean:    MetricSettings{Enabled: true},
		RiakNodeReadRepairCount:      MetricSettings{Enabled: true},
		RiakVnodeIndexOperationCount: MetricSettings{Enabled: true},
		RiakVnodeOperationCount:      MetricSettings{Enabled: true},
	}
	observedZapCore, observedLogs := observer.New(zap.WarnLevel)
	settings := receivertest.NewNopCreateSettings()
	settings.Logger = zap.New(observedZapCore)
	mb := NewMetricsBuilder(metricsSettings, settings, WithStartTime(start))

	assert.Equal(t, 0, observedLogs.Len())

	mb.RecordRiakMemoryLimitDataPoint(ts, 1)
	mb.RecordRiakNodeOperationCountDataPoint(ts, 1, AttributeRequest(1))
	mb.RecordRiakNodeOperationTimeMeanDataPoint(ts, 1, AttributeRequest(1))
	mb.RecordRiakNodeReadRepairCountDataPoint(ts, 1)
	mb.RecordRiakVnodeIndexOperationCountDataPoint(ts, 1, AttributeOperation(1))
	mb.RecordRiakVnodeOperationCountDataPoint(ts, 1, AttributeRequest(1))

	metrics := mb.Emit(WithRiakNodeName("attr-val"))

	assert.Equal(t, 1, metrics.ResourceMetrics().Len())
	rm := metrics.ResourceMetrics().At(0)
	attrCount := 0
	attrCount++
	attrVal, ok := rm.Resource().Attributes().Get("riak.node.name")
	assert.True(t, ok)
	assert.EqualValues(t, "attr-val", attrVal.Str())
	assert.Equal(t, attrCount, rm.Resource().Attributes().Len())

	assert.Equal(t, 1, rm.ScopeMetrics().Len())
	ms := rm.ScopeMetrics().At(0).Metrics()
	allMetricsCount := reflect.TypeOf(MetricsSettings{}).NumField()
	assert.Equal(t, allMetricsCount, ms.Len())
	validatedMetrics := make(map[string]struct{})
	for i := 0; i < ms.Len(); i++ {
		switch ms.At(i).Name() {
		case "riak.memory.limit":
			assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
			assert.Equal(t, "The amount of memory allocated to the node.", ms.At(i).Description())
			assert.Equal(t, "By", ms.At(i).Unit())
			assert.Equal(t, false, ms.At(i).Sum().IsMonotonic())
			assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
			dp := ms.At(i).Sum().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			validatedMetrics["riak.memory.limit"] = struct{}{}
		case "riak.node.operation.count":
			assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
			assert.Equal(t, "The number of operations performed by the node.", ms.At(i).Description())
			assert.Equal(t, "{operation}", ms.At(i).Unit())
			assert.Equal(t, true, ms.At(i).Sum().IsMonotonic())
			assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
			dp := ms.At(i).Sum().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			attrVal, ok := dp.Attributes().Get("request")
			assert.True(t, ok)
			assert.Equal(t, "put", attrVal.Str())
			validatedMetrics["riak.node.operation.count"] = struct{}{}
		case "riak.node.operation.time.mean":
			assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
			assert.Equal(t, "The mean time between request and response for operations performed by the node over the last minute.", ms.At(i).Description())
			assert.Equal(t, "us", ms.At(i).Unit())
			dp := ms.At(i).Gauge().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			attrVal, ok := dp.Attributes().Get("request")
			assert.True(t, ok)
			assert.Equal(t, "put", attrVal.Str())
			validatedMetrics["riak.node.operation.time.mean"] = struct{}{}
		case "riak.node.read_repair.count":
			assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
			assert.Equal(t, "The number of read repairs performed by the node.", ms.At(i).Description())
			assert.Equal(t, "{read_repair}", ms.At(i).Unit())
			assert.Equal(t, true, ms.At(i).Sum().IsMonotonic())
			assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
			dp := ms.At(i).Sum().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			validatedMetrics["riak.node.read_repair.count"] = struct{}{}
		case "riak.vnode.index.operation.count":
			assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
			assert.Equal(t, "The number of index operations performed by vnodes on the node.", ms.At(i).Description())
			assert.Equal(t, "{operation}", ms.At(i).Unit())
			assert.Equal(t, false, ms.At(i).Sum().IsMonotonic())
			assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
			dp := ms.At(i).Sum().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			attrVal, ok := dp.Attributes().Get("operation")
			assert.True(t, ok)
			assert.Equal(t, "read", attrVal.Str())
			validatedMetrics["riak.vnode.index.operation.count"] = struct{}{}
		case "riak.vnode.operation.count":
			assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
			assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
			assert.Equal(t, "The number of operations performed by vnodes on the node.", ms.At(i).Description())
			assert.Equal(t, "{operation}", ms.At(i).Unit())
			assert.Equal(t, true, ms.At(i).Sum().IsMonotonic())
			assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
			dp := ms.At(i).Sum().DataPoints().At(0)
			assert.Equal(t, start, dp.StartTimestamp())
			assert.Equal(t, ts, dp.Timestamp())
			assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
			assert.Equal(t, int64(1), dp.IntValue())
			attrVal, ok := dp.Attributes().Get("request")
			assert.True(t, ok)
			assert.Equal(t, "put", attrVal.Str())
			validatedMetrics["riak.vnode.operation.count"] = struct{}{}
		}
	}
	assert.Equal(t, allMetricsCount, len(validatedMetrics))
}

func TestNoMetrics(t *testing.T) {
	start := pcommon.Timestamp(1_000_000_000)
	ts := pcommon.Timestamp(1_000_001_000)
	metricsSettings := MetricsSettings{
		RiakMemoryLimit:              MetricSettings{Enabled: false},
		RiakNodeOperationCount:       MetricSettings{Enabled: false},
		RiakNodeOperationTimeMean:    MetricSettings{Enabled: false},
		RiakNodeReadRepairCount:      MetricSettings{Enabled: false},
		RiakVnodeIndexOperationCount: MetricSettings{Enabled: false},
		RiakVnodeOperationCount:      MetricSettings{Enabled: false},
	}
	observedZapCore, observedLogs := observer.New(zap.WarnLevel)
	settings := receivertest.NewNopCreateSettings()
	settings.Logger = zap.New(observedZapCore)
	mb := NewMetricsBuilder(metricsSettings, settings, WithStartTime(start))

	assert.Equal(t, 0, observedLogs.Len())
	mb.RecordRiakMemoryLimitDataPoint(ts, 1)
	mb.RecordRiakNodeOperationCountDataPoint(ts, 1, AttributeRequest(1))
	mb.RecordRiakNodeOperationTimeMeanDataPoint(ts, 1, AttributeRequest(1))
	mb.RecordRiakNodeReadRepairCountDataPoint(ts, 1)
	mb.RecordRiakVnodeIndexOperationCountDataPoint(ts, 1, AttributeOperation(1))
	mb.RecordRiakVnodeOperationCountDataPoint(ts, 1, AttributeRequest(1))

	metrics := mb.Emit()

	assert.Equal(t, 0, metrics.ResourceMetrics().Len())
}
